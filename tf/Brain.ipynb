{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "base_folder = \"./data\"\n",
    "file_name = os.path.join(base_folder, 'brains.zip')\n",
    "data_folder = os.path.join(base_folder, 'brains')\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    zip.extractall(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4514 files belonging to 2 classes.\n",
      "Using 3612 files for training.\n",
      "Found 4514 files belonging to 2 classes.\n",
      "Using 902 files for validation.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "folder_path = os.path.join(data_folder, 'Brain Tumor Data Set/Brain Tumor Data Set')\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    folder_path,\n",
    "  validation_split=0.2,\n",
    "  seed=123,\n",
    "    subset='training',\n",
    "  image_size=(512, 512),\n",
    "  batch_size=30)\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    folder_path,\n",
    "  validation_split=0.2,\n",
    "  seed=123,\n",
    "  image_size=(512, 512),\n",
    "    subset='validation',\n",
    "  batch_size=30)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(1)\n",
    "val_ds = val_ds.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 510, 510, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 255, 255, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 253, 253, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 124, 124, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 60, 60, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               58982912  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 59,224,257\n",
      "Trainable params: 59,224,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "filename = 'Brain.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filename,             \n",
    "                             monitor='val_loss',   \n",
    "                             verbose=1,            \n",
    "                             save_best_only=True,  \n",
    "                             mode='auto'           \n",
    "                            )\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',  \n",
    "                              patience=10,         \n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.8363 - acc: 0.7074 - val_loss: 0.5290 - val_acc: 0.7727\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52898, saving model to Brain.h5\n",
      "Epoch 2/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.4065 - acc: 0.8403 - val_loss: 0.3820 - val_acc: 0.8326\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52898 to 0.38203, saving model to Brain.h5\n",
      "Epoch 3/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.2556 - acc: 0.8995 - val_loss: 0.2862 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38203 to 0.28615, saving model to Brain.h5\n",
      "Epoch 4/60\n",
      "121/121 [==============================] - 25s 203ms/step - loss: 0.1903 - acc: 0.9277 - val_loss: 0.2282 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28615 to 0.22825, saving model to Brain.h5\n",
      "Epoch 5/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.1271 - acc: 0.9607 - val_loss: 0.1932 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.22825 to 0.19315, saving model to Brain.h5\n",
      "Epoch 6/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.1003 - acc: 0.9718 - val_loss: 0.1619 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19315 to 0.16187, saving model to Brain.h5\n",
      "Epoch 7/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0783 - acc: 0.9831 - val_loss: 0.1443 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16187 to 0.14429, saving model to Brain.h5\n",
      "Epoch 8/60\n",
      "121/121 [==============================] - 25s 201ms/step - loss: 0.0608 - acc: 0.9886 - val_loss: 0.1366 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14429 to 0.13661, saving model to Brain.h5\n",
      "Epoch 9/60\n",
      "121/121 [==============================] - 25s 201ms/step - loss: 0.0508 - acc: 0.9928 - val_loss: 0.1264 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13661 to 0.12640, saving model to Brain.h5\n",
      "Epoch 10/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0396 - acc: 0.9964 - val_loss: 0.1145 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.12640 to 0.11449, saving model to Brain.h5\n",
      "Epoch 11/60\n",
      "121/121 [==============================] - 25s 203ms/step - loss: 0.0344 - acc: 0.9975 - val_loss: 0.1043 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.11449 to 0.10429, saving model to Brain.h5\n",
      "Epoch 12/60\n",
      "121/121 [==============================] - 25s 204ms/step - loss: 0.0282 - acc: 0.9992 - val_loss: 0.1007 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.10429 to 0.10071, saving model to Brain.h5\n",
      "Epoch 13/60\n",
      "121/121 [==============================] - 25s 203ms/step - loss: 0.0250 - acc: 0.9983 - val_loss: 0.0927 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.10071 to 0.09274, saving model to Brain.h5\n",
      "Epoch 14/60\n",
      "121/121 [==============================] - 25s 204ms/step - loss: 0.0199 - acc: 0.9997 - val_loss: 0.0890 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09274 to 0.08899, saving model to Brain.h5\n",
      "Epoch 15/60\n",
      "121/121 [==============================] - 25s 201ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08899 to 0.08650, saving model to Brain.h5\n",
      "Epoch 16/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08650 to 0.08503, saving model to Brain.h5\n",
      "Epoch 17/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.08503 to 0.08283, saving model to Brain.h5\n",
      "Epoch 18/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08283 to 0.07921, saving model to Brain.h5\n",
      "Epoch 19/60\n",
      "121/121 [==============================] - 25s 203ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.07921 to 0.07835, saving model to Brain.h5\n",
      "Epoch 20/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07835\n",
      "Epoch 21/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.07835 to 0.07568, saving model to Brain.h5\n",
      "Epoch 22/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.07568 to 0.07487, saving model to Brain.h5\n",
      "Epoch 23/60\n",
      "121/121 [==============================] - 25s 202ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07487 to 0.07243, saving model to Brain.h5\n",
      "Epoch 24/60\n",
      "121/121 [==============================] - 25s 203ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.07243 to 0.07201, saving model to Brain.h5\n",
      "Epoch 25/60\n",
      "121/121 [==============================] - 25s 201ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.07201 to 0.07046, saving model to Brain.h5\n",
      "Epoch 26/60\n",
      "121/121 [==============================] - 24s 200ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.07046 to 0.06951, saving model to Brain.h5\n",
      "Epoch 27/60\n",
      "121/121 [==============================] - 25s 201ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0692 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06951 to 0.06918, saving model to Brain.h5\n",
      "Epoch 28/60\n",
      " 95/121 [======================>.......] - ETA: 4s - loss: 0.0042 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "history =  model.fit(\n",
    "    train_ds,\n",
    "    epochs=60,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
